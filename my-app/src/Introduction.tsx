export default function Introduction() {
    return <>
        <h1>Introduction to deepfakes</h1>
        <p>Image forgery usually refers to the manipulation of a digital image to conceal some meaningful or useful information about the image . Recently, deep learning-based techniques have been utilized in the image forgery field to create fake photos or videos that are sometimes called ‘Deepfakes’ . The term entered public consciousness in 2017 after semi-realistic pornographic clips ‘featuring’ celebrities generated by Deepfake technology were spread through a Reddit forum. These generation methods usually take into account multiple facial or posture artifacts and the use of deep convolutional networks to create realistic images or videos for human observers. With technology advancement, better neural network structure and techniques have been utilized to create Deepfakes of high quality.</p>
        <p>Although training a high performing Deepfake generator from scratch would require a lot of hard work, using a trained generator to create new artificial content is rather simple. There exists online software available for ordinary people to create Deepfakes on their own without knowledge about artificial intelligence or deep learning. This has led to more incidents of the technology being used maliciously against various public figures. For example, in the year following the above-stated celebrity Deepfake incident, a video ‘showing’ the former US president Barack Obama cursing and calling President Donald Trump names emerged. Despite the unlikelihood of the video being true due to notable visual inconsistency, it is believed that such incidents and maliciously produced 'news' has hurt public trust. It is critical to protect the identities of these entities from malicious acts that potentially lead to embarrassment or even irreversible geopolitical conflicts . However, with their natural exposure to much publicity due to their positions, there is usually lots of data available to train and deploy similar lip-syncing or face-swapping attacks. Additional research also indicates the possibility of creating seemingly realistic Deepfakes with only limited training data, perhaps just a few photos of the target. Thus, increasingly mature Deepfake technology has made it more and more difficult to detect Deepfakes. This has eroded the trust of the public in the authenticity of digitally recorded materials, since Deepfakes can potentially lead less-informed individuals to believe the false information conveyed in manipulated clips.</p>
        <p>The prevalence and easy accessibility of Deepfakes not only facilitates the spreading of misinformation but also poses unique challenges to multiple applications that require the data authenticity that the digital medium provides, especially in the field of computer vision and face recognition. Face-swapping Deepfakes have made identity theft, i.e. deliberately using another person’s identity for potential misconduct, much easier . On the other hand, there are also applications where Deepfake technology comes in handy for the benign purpose. One obvious application is the automatic after-processing of photos, helping resource-limited firms to organize more impactful marketing campaigns. It is also currently used for making some online training materials, which turn out to be helpful in the current situation of COVID 19, where a lot of video shoots have been called off . Some people also suggest that the development of Deepfake-related artificial intelligence technology could benefit the healthcare industry by auto-detecting illness symptoms. Thus, it is important to consider both malignant and benign applications when it comes to understanding the technology itself.</p>
        <p>To mitigate the negative impact of Deepfakes being used in malicious acts, large technology companies, including Google, Facebook, and Microsoft, have dedicated efforts to support and provide initiative for the development and accessibility of more accurate and reliable Deepfake-detection mechanisms. Google, in cooperation with renowned research universities, has published large-scale datasets for visual Deepfakes, which helps in future Deepfake detection efforts and benchmarking . Facebook and Microsoft jointly held a ‘Deepfake Detection Challenge’, hoping to encourage the development of and improvement upon existing detection algorithms . The result might seem insignificant, but still denotes an important step forward in coping with this constantly evolving technology and the potential impact it could have in the above-mentioned application fields. Recent research has also featured more carefully designed networks for Deepfake detection. Take two recent submissions in 2020 as examples. One makes use of a neural network to determine different facial parts, and it has a separate detector for any perturbation in each of the identified facial areas . The other aims to detect inconsistencies in the pixel-level perturbation made by the generator and study these convolutional traces that could lead to more confident predictions . Promising progress has been made with multiple Deepfake datasets and benchmarks. There are a few common types of deepfakes:</p>
        <h3>Reenactment Deepfake</h3>
        <p>
            A reenactment Deepfake uses a source image or video to drive the expression, posture, or movements of the target person in the output video or image. Lip syncing and head puppetry are two classic examples of this type of Deepfake generation approach, where the target head or lips are controlled in a way that mimics the source’s facial expression and gestures. In this kind of Deepfake approach, the target person’s identity is effectively stolen, leading to potential exploitation, like impersonation, or negatively affecting public opinions of the target person. The incident of the former US president Barack Obama mentioned above is an actual attack employed. MyVoiceYourFace  is a website that allows people with zero knowledge about deep learning to generate reenactment Deepfakes with only a source picture and a target video as input.
        </p>
        <h3>Replacement Deepfake</h3>
        <p>
            On the other hand, a replacement Deepfake extracts contents, usually facial features of the victim, from a source image or video and places them on the image or video of the target person. Using this approach, the identity of the person in the target video is usually not preserved but instead is swapped with the identity of the victim. Face swapping is one example of this approach of Deepfake generation, where only the face of the victim is switched with the face of the person in the target videos, creating a falsified record that the victim has done something which he/she hasn't done. One real-life example was some fake porn generated in 2017, where the faces of celebrities or politicians were swapped with the faces of porn stars in pornographic. This attack can create fake hidden dirt to be used to embarrass victims or for blackmailing. Deepfakes web β ] is another website portal that allows users to easily generate replacement Deepfakes by providing two videos, one for the source and one for the target.
        </p>
        <h3>Other forms of deepfake</h3>
        <p>
            There are also other forms of Deepfakes like editing and synthesis Deepfakes, which specialize in creating a fake identity. An editing Deepfake modifies target attributes, like a person’s age, hairstyle, or ethnicity, while a synthesis Deepfake is a collection of facial features of different people in which a new identity is created based on specified input attributes. Instead of impersonating the identities of victims, these two methods might generate non-existing personas. Thus, they are more commonly used in the gaming and filming industry than in actual attacks against targeted people.
        </p>
    </>
}
